<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TensorGrad Documentation</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css">
    <style>
        body { max-width: 800px; margin: 0 auto; padding: 20px; }
        pre { background: #f5f5f5; padding: 15px; border-radius: 5px; }
        code { background: #f5f5f5; padding: 2px 5px; border-radius: 3px; }
        .warning { background: #fff3cd; padding: 15px; border-radius: 5px; }
    </style>
</head>
<body>
    <h1>TensorGrad Documentation</h1>
    
    <p>TensorGrad is a tensor & deep learning framework that combines PyTorch's computational power with SymPy's symbolic manipulation capabilities.</p>

    <h2>Quick Links</h2>
    <ul>
        <li><a href="/docs/api/">API Reference</a></li>
        <li><a href="/docs/guide.html">User Guide</a></li>
        <li><a href="https://github.com/thomasahle/tensorgrad/blob/main/paper/cookbook.pdf">Tensor Cookbook (PDF)</a></li>
    </ul>

    <h2>Key Features</h2>
    <ul>
        <li>Tensor diagram manipulation for high dimensional tensors</li>
        <li>Automatic differentiation with symbolic computation</li>
        <li>Integration with PyTorch Named Tensors</li>
        <li>Visualization tools for tensor networks</li>
    </ul>

    <h2>Installation</h2>
    <pre><code>pip install tensorg</code></pre>

    <div class="warning">
        <p><strong>Note:</strong> For visualizations, additional LaTeX packages are required:</p>
        <pre><code>apt-get install texlive-luatex
apt-get install texlive-latex-extra
apt-get install texlive-fonts-extra
apt-get install poppler-utils</code></pre>
    </div>

    <h2>Basic Example</h2>
    <pre><code>from tensorgrad import Variable
import tensorgrad.functions as F
from sympy import symbols

# Create symbolic dimensions
b, x, y = symbols("b x y")

# Define variables
X = Variable("X", b, x)
Y = Variable("Y", b, y)
W = Variable("W", x, y)

# Create computation
XWmY = X @ W - Y
l2 = XWmY @ XWmY

# Compute gradient
grad = l2.grad(W)

# The result can be:
# - Evaluated with actual tensors
# - Visualized as a tensor diagram
# - Converted to PyTorch code</code></pre>

    <p>For more detailed examples and explanations, check out the <a href="/docs/guide.html">User Guide</a>.</p>
</body>
</html>
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TensorGrad User Guide</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css">
    <style>
        body { max-width: 800px; margin: 0 auto; padding: 20px; }
        pre { background: #f5f5f5; padding: 15px; border-radius: 5px; }
        code { background: #f5f5f5; padding: 2px 5px; border-radius: 3px; }
        .note { background: #e7f5ff; padding: 15px; border-radius: 5px; }
    </style>
</head>
<body>
    <h1>TensorGrad User Guide</h1>

    <h2>Core Concepts</h2>

    <h3>Variables and Dimensions</h3>
    <p>In TensorGrad, tensors are created with symbolic dimensions using SymPy symbols:</p>
    <pre><code>from sympy import symbols
from tensorgrad import Variable

# Create dimension symbols
i, j = symbols("i j")

# Create a matrix variable
X = Variable("X", i, j)

# Create a symmetric matrix
S = Variable("S", i=i, j=i).with_symmetries("i j")</code></pre>

    <h3>Basic Operations</h3>
    <p>TensorGrad supports standard tensor operations:</p>
    <pre><code>import tensorgrad.functions as F

# Matrix multiplication (using @)
C = A @ B

# Element-wise operations
y = F.exp(x)
z = F.relu(x)

# Reductions
s = F.sum(x, ["i"])
m = F.max(x, ["i"])

# Softmax
p = F.softmax(x, dim="i")</code></pre>

    <h3>Gradients</h3>
    <p>Computing gradients is a core feature:</p>
    <pre><code># L2 loss example
XWmY = X @ W - Y
loss = F.frobenius2(XWmY)  # ||XW - Y||Â²
grad = loss.grad(W)

# Cross entropy example
logits = Variable("logits", ["C"])
target = Variable("target", ["C"])
ce = F.cross_entropy(logits, target, dim="C")
grad = ce.grad(logits)</code></pre>

    <h3>Expectations</h3>
    <p>TensorGrad can compute expectations of arbitrary functions with respect to Gaussian tensors:</p>
    <pre><code>from tensorgrad.extras.expectation import Expectation

# Define mean and covariance
mu = Variable("mu", i, j)
covar = Variable("covar", i, j, i2=i, j2=j)

# Compute expectation
E = Expectation(expr, wrt=X, mu=mu, covar=covar)</code></pre>

    <h2>Advanced Features</h2>

    <h3>Tensor Networks</h3>
    <p>TensorGrad provides a graph-based syntax for complex tensor operations:</p>
    <pre><code># Using graph syntax for tensor contractions
expr = F.graph("""
    A -i- X0 -j- B
    X0 -k- C
    B -l- D
""", A=A, X0=X, B=B, C=C, D=D)</code></pre>

    <h3>Neural Network Components</h3>
    <p>Common neural network operations are supported:</p>
    <pre><code># Convolution
data = Variable("data", ["b", "c", "w", "h"])
unfold = Convolution("w", "j", "w2") @ Convolution("h", "i", "h2")
kernel = Variable("kernel", ["c", "i", "j", "c2"])
conv = data @ unfold @ kernel

# Attention mechanism
query = W_q @ X
key = W_k @ X
value = W_v @ X
logits = F.dot(query, key, ["inner"])
attention = F.softmax(logits, dim="seq_k")</code></pre>

    <div class="note">
        <h3>Integration with PyTorch</h3>
        <p>TensorGrad expressions can be evaluated using PyTorch tensors:</p>
        <pre><code>import torch

# Create actual tensors
values = {
    X: torch.randn(3, 4, names=('i', 'j')),
    W: torch.randn(4, 2, names=('j', 'k'))
}

# Evaluate the expression
result = expr.evaluate(values)</code></pre>
    </div>

    <h2>Visualization</h2>
    <p>TensorGrad can visualize tensor networks in multiple formats:</p>
    <pre><code># Generate TikZ diagram
from tensorgrad.serializers.to_tikz import to_tikz
tikz_code = to_tikz(expr)

# Generate Graphviz diagram
from tensorgrad.serializers.to_graphviz import to_graphviz
dot_code = to_graphviz(expr)</code></pre>

    <p>For more examples and detailed API documentation, see the <a href="/docs/api/">API Reference</a>.</p>
</body>
</html>
