<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.5">
<title>tensorgrad.testutils API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tensorgrad.testutils</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="tensorgrad.testutils.assert_close"><code class="name flex">
<span>def <span class="ident">assert_close</span></span>(<span>actual, expected, rtol=0.0001, atol=1e-05)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def assert_close(actual, expected, rtol=1e-4, atol=1e-5):
    assert set(actual.names) == set(expected.names), f&#34;{actual.names=} != {expected.names=}&#34;
    actual = actual.align_to(*expected.names).rename(None)
    expected = expected.expand_as(actual).rename(None)
    torch.testing.assert_close(actual, expected, rtol=rtol, atol=atol)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tensorgrad.testutils.atlas_generate_random_tensor_expression"><code class="name flex">
<span>def <span class="ident">atlas_generate_random_tensor_expression</span></span>(<span>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def atlas_generate_random_tensor_expression():
    atlas = nx.graph_atlas_g()
    for _ in range(100):
        gs = [random.choice(atlas)]
        while random.random() &lt; 0.5:
            gs.append(random.choice(atlas))</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tensorgrad.testutils.broadcast_tensors"><code class="name flex">
<span>def <span class="ident">broadcast_tensors</span></span>(<span>left_torch, right_torch)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def broadcast_tensors(left_torch, right_torch):
    all_dims = list(set(left_torch.names) | set(right_torch.names))
    left_aligned = left_torch.align_to(*all_dims)
    right_aligned = right_torch.align_to(*all_dims)
    return left_aligned, right_aligned</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tensorgrad.testutils.generate_copy"><code class="name flex">
<span>def <span class="ident">generate_copy</span></span>(<span>dim: int, edges: Iterable[str])</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_copy(dim: int, edges: Iterable[str]):
    copy = torch.zeros((dim,) * len(edges))
    for i in range(dim):
        copy[(i,) * len(edges)] = 1
    return copy.rename(*edges)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tensorgrad.testutils.generate_random_tensor_expression"><code class="name flex">
<span>def <span class="ident">generate_random_tensor_expression</span></span>(<span>max_size: int) ‑> Tuple[<a title="tensorgrad.tensor.Tensor" href="tensor.html#tensorgrad.tensor.Tensor">Tensor</a>, torch.Tensor, Dict[<a title="tensorgrad.tensor.Variable" href="tensor.html#tensorgrad.tensor.Variable">Variable</a>, torch.Tensor]]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_random_tensor_expression(
    max_size: int,
) -&gt; Tuple[Tensor, torch.Tensor, Dict[Variable, torch.Tensor]]:
    def generate_recursive(size: int, variables: Dict[Variable, torch.Tensor]) -&gt; Tuple[Tensor, torch.Tensor]:
        if size == 1:
            # Base case: single variable or constant with different edge configurations
            # if random.random() &lt; 0.5 and variables:
            if random.random() &lt; 1:
                var, tensor = random.choice(list(variables.items()))
                return var, tensor
            else:
                tensor_class, torch_func = random.choice(
                    [(Zero, torch.zeros), (Ones, torch.ones), (Copy, generate_copy)]
                )
                edges = random.choice([[&#34;a&#34;], [&#34;a&#34;, &#34;b&#34;], [&#34;a&#34;, &#34;b&#34;, &#34;c&#34;]])
                if tensor_class == Copy:
                    dim = random.choice([2, 3])
                    return tensor_class(edges), torch_func(dim, edges)
                else:
                    dims = tuple(random.choice([2, 3]) for _ in range(len(edges)))
                    return tensor_class(edges), torch_func(dims, names=edges)
        else:
            # Recursive case: generate subexpressions and combine them
            left_size = random.randint(1, size // 2 + 1)
            right_size = size - left_size

            for _ in range(10):
                left_tensor, left_torch = generate_recursive(left_size, variables)
                right_tensor, right_torch = generate_recursive(right_size, variables)

                if random.random() &lt; 0.2:
                    left_aligned, right_aligned = broadcast_tensors(left_torch, right_torch)
                    try:
                        return left_tensor + right_tensor, left_aligned + right_aligned
                    except RuntimeError as e:
                        # print(e)
                        continue
                else:
                    contracted = set(left_tensor.edges) &amp; set(right_tensor.edges)
                    rhs = &#34;&#34;.join(e for e in left_torch.names + right_torch.names if e not in contracted)
                    eq = f&#34;{&#39;&#39;.join(left_torch.names)},{&#39;&#39;.join(right_torch.names)}-&gt;{rhs}&#34;
                    try:
                        torch_result = torch.einsum(eq, left_torch.rename(None), right_torch.rename(None))
                    except RuntimeError as e:
                        # print(eq, e)
                        continue
                    return left_tensor @ right_tensor, torch_result.rename(*rhs)
            # Give up
            raise ValueError(&#34;Failed to generate random tensor expression&#34;)

    variables = {}
    ds = {c: random.choice([2, 3]) for c in &#34;abc&#34;}
    for var_name in &#34;xyztuv&#34;:
        edges = {&#34;x&#34;: [&#34;a&#34;], &#34;y&#34;: [&#34;b&#34;], &#34;z&#34;: [&#34;c&#34;], &#34;t&#34;: [&#34;a&#34;, &#34;b&#34;], &#34;u&#34;: [&#34;a&#34;, &#34;b&#34;], &#34;v&#34;: [&#34;a&#34;, &#34;b&#34;, &#34;c&#34;]}[
            var_name
        ]
        # dims = [random.choice([2, 3]) for _ in range(len(edges))]
        dims = [ds[e] for e in edges]
        variables[Variable(var_name, edges)] = torch.randn(dims, names=edges)

    while True:
        try:
            expr, tensor = generate_recursive(max_size, variables)
            return expr, tensor, variables
        except ValueError:
            continue</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tensorgrad.testutils.make_random_tree"><code class="name flex">
<span>def <span class="ident">make_random_tree</span></span>(<span>nodes: int)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_random_tree(nodes: int):
    components = [i for i in range(nodes)]

    def find(x):
        if components[x] != x:
            components[x] = find(components[x])
        return components[x]

    def union(x, y):
        components[find(x)] = find(y)

    edges = []
    adj = [[] for _ in range(nodes)]
    while len(edges) &lt; nodes - 1:
        x, y = random.randint(0, nodes - 1), random.randint(0, nodes - 1)
        if len(adj[x]) &lt; 3 and len(adj[y]) &lt; 3 and find(x) != find(y):
            union(x, y)
            edges.append((x, y))
            adj[x].append(y)
            adj[y].append(x)

    # 3n edges, n-1 used, 2(n-1) used for connections, n+1 leaf nodes, 1 free edge left.
    names = string.ascii_uppercase
    vectors = []
    variables = []
    for i in range(nodes):
        ts = [f&#34;{names[min(i,j)]}|{names[max(i,j)]}&#34; for j in adj[i]]
        while len(ts) &lt; 3 and len(vectors) &lt; nodes + 1:
            vi = len(vectors)
            vectors.append(Variable(f&#34;V{vi}&#34;, f&#34;v{vi}&#34;))
            ts.append(f&#34;v{vi}&#34;)
        if len(ts) != 3:
            ts.append(&#34;free&#34;)
        variables.append(Variable(names[i], ts))

    return vectors, variables</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tensorgrad.testutils.rand_values"><code class="name flex">
<span>def <span class="ident">rand_values</span></span>(<span>variables: Iterable[<a title="tensorgrad.tensor.Variable" href="tensor.html#tensorgrad.tensor.Variable">Variable</a>],<br>shape: Dict[sympy.core.symbol.Symbol, int] = {}) ‑> dict[<a title="tensorgrad.tensor.Variable" href="tensor.html#tensorgrad.tensor.Variable">Variable</a>, torch.Tensor]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rand_values(variables: Iterable[Variable], shape: Dict[Symbol, int] = {}) -&gt; dict[Variable, torch.Tensor]:
    values = {}
    for v in variables:
        if v.order == 0:
            values[v] = torch.randn([])
        else:
            edges, sizes = zip(*v.shape.items())
            values[v] = torch.randn([shape[s] for s in sizes], names=edges)
    return values</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tensorgrad.testutils.random_tensor_expr"><code class="name flex">
<span>def <span class="ident">random_tensor_expr</span></span>(<span>max_depth=4, max_dim=4) ‑> tuple[<a title="tensorgrad.tensor.Tensor" href="tensor.html#tensorgrad.tensor.Tensor">Tensor</a>, torch.Tensor, dict[<a title="tensorgrad.tensor.Variable" href="tensor.html#tensorgrad.tensor.Variable">Variable</a>, torch.Tensor]]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def random_tensor_expr(max_depth=4, max_dim=4) -&gt; tuple[Tensor, torch.Tensor, dict[Variable, torch.Tensor]]:
    assert max_dim &gt;= 1
    if max_dim == 1:
        symbols_list = [symbols(&#34;a&#34;)]
    else:
        symbols_list = symbols(&#34; &#34;.join(string.ascii_letters[:max_dim]))
    sizes = {s: random.randrange(1, 2 * max_dim + 1) for s in symbols_list}
    vars = [
        (
            Variable(f&#34;var_{symbols}&#34;, *symbols),
            torch.randn([sizes[s] for s in symbols], names=list(map(str, symbols))),
        )
        for r in range(1, len(symbols_list) + 1)
        for symbols in itertools.combinations(symbols_list, r)
    ]

    def inner(depth):
        if depth == 0:
            # return random.choice(random.choice([vars, copys]))
            return random.choice(vars)
        left, left_torch = inner(depth - 1)
        right, right_torch = inner(depth - 1)
        rand = random.random()
        if rand &lt; 0.3:
            left_aligned, right_aligned = broadcast_tensors(left_torch, right_torch)
            k = random.randint(-2, 4)
            return left * right**k, left_aligned * right_aligned**k
        if rand &lt; 0.6:
            left_aligned, right_aligned = broadcast_tensors(left_torch, right_torch)
            return left + right, left_aligned + right_aligned
        else:
            contracted = left.edges &amp; right.edges
            rhs = &#34;&#34;.join(e for e in left_torch.names + right_torch.names if e not in contracted)
            eq = f&#34;{&#39;&#39;.join(left_torch.names)},{&#39;&#39;.join(right_torch.names)}-&gt;{rhs}&#34;
            torch_result = torch.einsum(eq, left_torch.rename(None), right_torch.rename(None))
            return left @ right, torch_result.rename(*rhs)

    tensor, tensor_torch = inner(depth=max_depth)
    return tensor, tensor_torch, {v: t for v, t in vars}</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="tensorgrad.testutils.random_tensor_expr2"><code class="name flex">
<span>def <span class="ident">random_tensor_expr2</span></span>(<span>max_depth=4, max_dim=4) ‑> tuple[<a title="tensorgrad.tensor.Tensor" href="tensor.html#tensorgrad.tensor.Tensor">Tensor</a>, torch.Tensor, dict]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def random_tensor_expr2(max_depth=4, max_dim=4) -&gt; tuple[Tensor, torch.Tensor, dict]:
    # 1) Randomized symbol set
    chosen_letters = random.sample(string.ascii_lowercase, max_dim)
    symbols_list = symbols(&#34; &#34;.join(chosen_letters))

    # 2) More interesting shape selection
    interesting_sizes = [1, 2, 3, 4, 8]
    sizes = {s: random.choice(interesting_sizes) for s in symbols_list}

    # 3) Create a smaller subset of variables / copies
    #    instead of enumerating all combinations
    possible_combinations = list(
        itertools.chain.from_iterable(
            itertools.combinations(symbols_list, r) for r in range(1, len(symbols_list) + 1)
        )
    )
    random.shuffle(possible_combinations)

    # let&#39;s only keep up to 5 random combos
    combos_subset = possible_combinations[:5]

    vars_pool = []
    for combo in combos_subset:
        name = &#34;_&#34;.join(str(x) for x in combo)
        var = Variable(f&#34;var_{name}&#34;, *combo)
        t = torch.randn([sizes[s] for s in combo], names=[str(s) for s in combo])
        vars_pool.append((var, t))

    # same for copys
    copys_pool = []
    for s0 in symbols_list:
        # generate 2 random combos for each symbol
        local_combos = random.sample(possible_combinations, k=2)
        for combo in local_combos:
            cpy = Copy(s0, *map(str, combo))
            copy_torch = generate_copy(sizes[s0], list(map(str, combo)))
            copys_pool.append((cpy, copy_torch))

    LEAF_POOL = vars_pool + copys_pool

    def inner(depth):
        # Base case
        if depth == 0 or random.random() &lt; 0.2:
            return random.choice(LEAF_POOL)

        # Recur on sub-expressions
        left_expr, left_torch = inner(depth - 1)
        right_expr, right_torch = inner(depth - 1)

        # Randomly pick an operation
        op = random.choice([&#34;add&#34;, &#34;einsum&#34;])
        if op == &#34;add&#34;:
            left_aligned, right_aligned = broadcast_tensors(left_torch, right_torch)
            return (left_expr + right_expr, left_aligned + right_aligned)
        else:
            # create a random einsum pattern
            contracted = left_expr.edges &amp; right_expr.edges
            rhs = &#34;&#34;.join(e for e in left_torch.names + right_torch.names if e not in contracted)
            eq = f&#34;{&#39;&#39;.join(left_torch.names)},{&#39;&#39;.join(right_torch.names)}-&gt;{rhs}&#34;
            torch_result = torch.einsum(eq, left_torch.rename(None), right_torch.rename(None))
            return (left_expr @ right_expr, torch_result.rename(*rhs))

    expr, expr_torch = inner(max_depth)

    # 4) (Optional) final random mutation pass
    # e.g., with 10% chance, multiply top-level by a scalar
    if random.random() &lt; 0.1:
        scalar = random.choice([0.5, -1.0, 2.0])
        expr = scalar * expr
        expr_torch = expr_torch * scalar

    # 5) Build final variable dict
    #    (the union of those used in vars_pool)
    var_dict = {v: t for (v, t) in vars_pool}

    return expr, expr_torch, var_dict</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tensorgrad" href="index.html">tensorgrad</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="tensorgrad.testutils.assert_close" href="#tensorgrad.testutils.assert_close">assert_close</a></code></li>
<li><code><a title="tensorgrad.testutils.atlas_generate_random_tensor_expression" href="#tensorgrad.testutils.atlas_generate_random_tensor_expression">atlas_generate_random_tensor_expression</a></code></li>
<li><code><a title="tensorgrad.testutils.broadcast_tensors" href="#tensorgrad.testutils.broadcast_tensors">broadcast_tensors</a></code></li>
<li><code><a title="tensorgrad.testutils.generate_copy" href="#tensorgrad.testutils.generate_copy">generate_copy</a></code></li>
<li><code><a title="tensorgrad.testutils.generate_random_tensor_expression" href="#tensorgrad.testutils.generate_random_tensor_expression">generate_random_tensor_expression</a></code></li>
<li><code><a title="tensorgrad.testutils.make_random_tree" href="#tensorgrad.testutils.make_random_tree">make_random_tree</a></code></li>
<li><code><a title="tensorgrad.testutils.rand_values" href="#tensorgrad.testutils.rand_values">rand_values</a></code></li>
<li><code><a title="tensorgrad.testutils.random_tensor_expr" href="#tensorgrad.testutils.random_tensor_expr">random_tensor_expr</a></code></li>
<li><code><a title="tensorgrad.testutils.random_tensor_expr2" href="#tensorgrad.testutils.random_tensor_expr2">random_tensor_expr2</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.5</a>.</p>
</footer>
</body>
</html>
